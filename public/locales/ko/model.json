{
  "configuration": "설정",
  "model": "모델",
  "token": {
    "label": "최대 토큰",
    "description": "채팅 완성에서 생성할 최대 토큰 수입니다. 입력 토큰과 생성된 토큰의 총 길이는 모델의 컨텍스트 길이로 제한됩니다."
  },
  "default": "기본값",
  "temperature": {
    "label": "온도",
    "description": "0에서 2 사이의 샘플링 온도를 설정합니다. 0.8과 같이 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같이 낮은 값은 더 집중적이고 결정적인 출력을 만듭니다. 일반적으로 이 값이나 top p 중 하나만 조정하는 것을 권장합니다. (기본값: 1)"
  },
  "presencePenalty": {
    "label": "존재 페널티",
    "description": "-2.0에서 2.0 사이의 숫자입니다. 양수 값은 지금까지 텍스트에 등장한 토큰에 기반하여 새로운 토큰에 페널티를 부과하여, 모델이 새로운 주제에 대해 이야기할 가능성을 높입니다. (기본값: 0)"
  },
  "topP": {
    "label": "상위-p",
    "description": "0에서 1 사이의 숫자입니다. 온도를 이용한 샘플링의 대안으로, 핵 샘플링이라고 불립니다. 모델은 상위 p 확률 질량을 구성하는 토큰의 결과만 고려합니다. 따라서 0.1은 상위 10% 확률 질량을 구성하는 토큰만 고려된다는 의미입니다. 일반적으로 이 값이나 온도 중 하나만 조정하는 것을 권장합니다. (기본값: 1)"
  },
  "frequencyPenalty": {
    "label": "빈도 페널티",
    "description": "-2.0에서 2.0 사이의 숫자입니다. 양수 값은 지금까지 텍스트에서의 기존 빈도에 기반하여 새로운 토큰에 페널티를 부과하여, 모델이 같은 줄을 그대로 반복할 가능성을 줄입니다. (기본값: 0)"
  },
  "defaultChatConfig": "기본 채팅 설정",
  "defaultSystemMessage": "기본 시스템 메시지",
  "resetToDefault": "기본값으로 초기화"
}